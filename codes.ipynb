{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "_2TCtLSQXv1R"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import time\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import models\n",
    "from collections import namedtuple\n",
    "from PIL import Image\n",
    "import copy\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import make_grid\n",
    "\n",
    "from random import randint\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, models, InputExample, losses, evaluation\n",
    "\n",
    "\n",
    "# check GPU availability\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pickle\n",
    "\n",
    "import nltk\n",
    "import tqdm\n",
    "from torchvision import transforms\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "71pe-gGDucds",
    "tags": []
   },
   "source": [
    "# drawing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "71pe-gGDucds",
    "tags": []
   },
   "source": [
    "## data preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /home/jupyter/.kaggle/kaggle.json'\n",
      "Downloading vqadrawing.zip to /home/jupyter/dl4cv-film-vqa\n",
      " 99%|██████████████████████████████████████▊| 3.95G/3.97G [00:34<00:00, 123MB/s]\n",
      "100%|███████████████████████████████████████| 3.97G/3.97G [00:34<00:00, 124MB/s]\n"
     ]
    }
   ],
   "source": [
    "# download the dataset\n",
    "!kaggle datasets download -d dcairoli/vqadrawing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('VQA_Dataset/train_questions_annotations.json') as json_file:\n",
    "    data = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = list(data.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Is the sun shining?', 'image_id': '9871', 'answer': 'yes'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[65]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01e5b1f11526442bbedb2af0115745ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.18k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a6a9fcf52a54c38a95623caa2877298",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af400207c99843f18fa083e099ea7792",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6112cf0574704ee7986022732c02fd69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da71e0a193b44d5abfdb7b4addd08d4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19f611340f8747ca977a041b08ea721b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/39.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32be7879b334423aa0074f95280e5a98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f9d6c79d3ea4da2947f5e7054fb596f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3285e9373864fdc8de516b9498415c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a629c711823c4c9b9a57d3ab8caa4683",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ca5c6bc73944d1bb8d85ac8a95ca3e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/363 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a767b8d68c484880b98297095d8aa259",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/13.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "531c0554dbb54492bd11e0d076886cde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76107feecebb4adda906a3f2a39ce932",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create data\n",
    "embedder = SentenceTransformer('all-mpnet-base-v2')\n",
    "result = []\n",
    "word_index = 1\n",
    "answer_index = 0\n",
    "answer_dic = {}\n",
    "for i in range(len(data)):\n",
    "    response = data[i]['answer']\n",
    "    image = data[i]['image_id']\n",
    "    question = data[i]['question']\n",
    "    question_embedding = embedder.encode(question, convert_to_tensor=True).to('cpu')\n",
    "    if len(response.split(','))>1:\n",
    "        for j in range(len(response.split(','))):\n",
    "            if j==0:\n",
    "                answer_word = str(response.split(',')[j]).lower()\n",
    "            else:\n",
    "                answer_word = str(response.split(',')[j][1:]).lower()\n",
    "            try:\n",
    "                answer = answer_dic[answer_word]\n",
    "            except:\n",
    "                answer = answer_index\n",
    "                answer_dic[answer_word] = answer_index\n",
    "                answer_index += 1\n",
    "            result.append((image,question,question_embedding,answer,response))\n",
    "    else:\n",
    "        answer_word = str(response).lower()\n",
    "        try:\n",
    "            answer = answer_dic[answer_word]\n",
    "        except:\n",
    "            answer = answer_index\n",
    "            answer_dic[answer_word] = answer_index\n",
    "            answer_index += 1\n",
    "        result.append((image,question,question_embedding,answer,response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data.pickle', 'wb') as handle:\n",
    "    pickle.dump(result, handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['man',\n",
       " 'blanket',\n",
       " 'bench',\n",
       " 'yes',\n",
       " 'no',\n",
       " 'brown',\n",
       " '1',\n",
       " 'gray',\n",
       " 'soccer',\n",
       " '3',\n",
       " 'playing',\n",
       " 'sitting',\n",
       " 'food',\n",
       " '2',\n",
       " 'orange',\n",
       " 'red',\n",
       " 'yellow',\n",
       " 'blue',\n",
       " 'baseball',\n",
       " 'nothing',\n",
       " 'dog',\n",
       " 'tree',\n",
       " 'stool',\n",
       " '0',\n",
       " 'woman',\n",
       " 'log',\n",
       " 'bike',\n",
       " 'floor',\n",
       " '4',\n",
       " 'table',\n",
       " 'standing',\n",
       " 'sleeping',\n",
       " 'plant',\n",
       " 'apple',\n",
       " 'black',\n",
       " 'squirrel',\n",
       " 'grass',\n",
       " 'left',\n",
       " 'bone',\n",
       " 'girl',\n",
       " 'white',\n",
       " '5',\n",
       " 'wine',\n",
       " 'couch',\n",
       " 'sandbox',\n",
       " 'chair',\n",
       " 'cat',\n",
       " 'pie',\n",
       " 'watermelon',\n",
       " 'book',\n",
       " 'green',\n",
       " 'monkey bars',\n",
       " 'boy',\n",
       " 'right',\n",
       " 'rug',\n",
       " 'football',\n",
       " 'sunny',\n",
       " 'bird']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get answer space\n",
    "answer_index = 0\n",
    "answer_dic = {}\n",
    "for i in range(len(data)):\n",
    "    response = data[i]['answer']\n",
    "    if len(response.split(','))>1:\n",
    "        for j in range(len(response.split(','))):\n",
    "            if j==0:\n",
    "                answer_word = str(response.split(',')[j]).lower()\n",
    "            else:\n",
    "                answer_word = str(response.split(',')[j][1:]).lower()\n",
    "            try:\n",
    "                answer = answer_dic[answer_word]\n",
    "            except:\n",
    "                answer = answer_index\n",
    "                answer_dic[answer_word] = answer_index\n",
    "                answer_index += 1\n",
    "    else:\n",
    "        answer_word = str(response).lower()\n",
    "        try:\n",
    "            answer = answer_dic[answer_word]\n",
    "        except:\n",
    "            answer = answer_index\n",
    "            answer_dic[answer_word] = answer_index\n",
    "            answer_index += 1\n",
    "\n",
    "answer_dic\n",
    "answer_space = list(answer_dic.keys())\n",
    "answer_space"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gs97AkXNcTyr",
    "tags": []
   },
   "source": [
    "## dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if data.pickle exists\n",
    "with open('data.pickle', 'rb') as handle:\n",
    "    data=pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "58832"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58832\n",
      "47065\n",
      "37652\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "print(len(data))\n",
    "\n",
    "split = int(len(data)*0.8)\n",
    "print(split)\n",
    "\n",
    "random.shuffle(data)\n",
    "dev_data = data[:split]\n",
    "test_data = data[split:]\n",
    "\n",
    "split = int(len(dev_data)*0.8)\n",
    "print(split)\n",
    "train_data = dev_data[:split]\n",
    "val_data = dev_data[split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37652\n",
      "9413\n",
      "11767\n"
     ]
    }
   ],
   "source": [
    "print(len(train_data))\n",
    "print(len(val_data))\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "\n",
    "from torchvision import transforms as T\n",
    "\n",
    "class DRAW(Dataset):\n",
    "    def __init__(self, data, transform=None):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        imgfile, question, question_embedding, answer_label, response = self.data[index]\n",
    "        img = Image.open(os.path.join('VQA_Dataset/Images', imgfile+'.png')).convert('RGB')\n",
    "        img = self.transform(img)\n",
    "\n",
    "        return img, question_embedding, question, answer_label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "transform = T.Compose([\n",
    "    T.Resize(224),\n",
    "    T.Pad(4),\n",
    "    T.RandomCrop([224, 224]),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.5, 0.5, 0.5],\n",
    "                        std=[0.5, 0.5, 0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(DRAW(data=train_data, transform=transform), batch_size=12, shuffle=True)\n",
    "training_loader_iter = iter(train_loader)\n",
    "img, question_embedding, question, answer_label = next(training_loader_iter)\n",
    "img = img.to(device)\n",
    "answer_label = answer_label.to(device)\n",
    "question_embedding = question_embedding.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fcHvXpOkvNF9"
   },
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "MDCErbX205u5"
   },
   "outputs": [],
   "source": [
    "from torchvision.models import resnet101, ResNet101_Weights\n",
    "import torchvision\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13.1+cu113\n"
     ]
    }
   ],
   "source": [
    "print(torchvision.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "executionInfo": {
     "elapsed": 315,
     "status": "ok",
     "timestamp": 1669492949076,
     "user": {
      "displayName": "Kaan Ozdogru",
      "userId": "11475962799414321632"
     },
     "user_tz": 300
    },
    "id": "hzLHomWQvPA7"
   },
   "outputs": [],
   "source": [
    "SENTENCE_TRANSFORMER_DIM = 384\n",
    "SENTENCE_TRANSFORMER_DIM = 768\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, input_channels, output_channels):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv = nn.Conv2d(input_channels, output_channels, 4, 2, 1)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.bn = nn.BatchNorm2d(output_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.relu(x)\n",
    "        \n",
    "\n",
    "        return x\n",
    "\n",
    "class stem(nn.Module):\n",
    "    def __init__(self, in_channels=1024, out_channels=128):\n",
    "        super(stem, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=0)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=0)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FeatureExtractor, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            CNN(3, 128),\n",
    "            CNN(128, 128),\n",
    "            CNN(128, 128),\n",
    "            CNN(128, 128),\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "class FeatureExtractor_resnet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FeatureExtractor_resnet, self).__init__()\n",
    "        self.cnn = getattr(torchvision.models, 'resnet101')(pretrained=True)\n",
    "        self.layers = [\n",
    "            self.cnn.conv1,\n",
    "            self.cnn.bn1,\n",
    "            self.cnn.relu,\n",
    "            self.cnn.maxpool,\n",
    "        ]\n",
    "        for i in range(3):\n",
    "            name = 'layer%d' % (i + 1)\n",
    "            self.layers.append(getattr(self.cnn, name))\n",
    "        self.model = torch.nn.Sequential(*self.layers)\n",
    "        #model.cuda()\n",
    "        self.model.eval()\n",
    "        #print(model)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "class FiLMBlock(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FiLMBlock, self).__init__()\n",
    "        \n",
    "\n",
    "    def forward(self, input, gamma_beta):\n",
    "        # b, ch, h, w = input.size()\n",
    "        batch =  input.size()[0]\n",
    "        height = input.size()[2]\n",
    "        width = input.size()[3]\n",
    "        features = input.size()[1]\n",
    "        # context_dim = context.size()[1]\n",
    "        gamma_beta = gamma_beta.unsqueeze(-1).unsqueeze(-1) # shape: [b, 2*ch, 1, 1]\n",
    "        gamma = gamma_beta[:,:features,:,:] # shape: [b, ch, 1, 1]\n",
    "        # print('gamma size should be [1,128,1,1]')\n",
    "        # print(gamma.size())\n",
    "        beta = gamma_beta[:,features:,:,:] # shape: [b, ch, 1, 1]\n",
    "        # print('beta size should be [1,128,1,1]')\n",
    "        # print(beta.size())\n",
    "        output = gamma * input + beta\n",
    "\n",
    "        return output\n",
    "\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, n_classes, prev_channels=128):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.conv = nn.Conv2d(prev_channels, 512, 1, 1, 0)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.global_max_pool = nn.AdaptiveMaxPool2d((1, 1))\n",
    "        self.mlp = nn.Sequential(nn.Linear(512, 1024),\n",
    "                                   nn.ReLU(inplace=True),\n",
    "                                   nn.Linear(1024, 1024),\n",
    "                                   nn.ReLU(inplace=True),\n",
    "                                   nn.Linear(1024, n_classes))\n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.global_max_pool(x)\n",
    "        x = x.view(x.size(0), x.size(1))\n",
    "        x = self.mlp(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "class resblock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(resblock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.film = FiLMBlock()\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "        self.film_generator = nn.Linear(SENTENCE_TRANSFORMER_DIM, out_channels * 2 ) # \n",
    "\n",
    "    def forward(self, x, context):\n",
    "        \n",
    "        # print(context.type())\n",
    "        film_params = self.film_generator(context) # shape: [b, num_filters * 2]\n",
    "        # print('film params size should be [1,256]')\n",
    "        # print(film_params.size())\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        identity = x\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.film(x, film_params)\n",
    "        x = self.relu2(x)\n",
    "\n",
    "        x = x+identity # instead of x+=identity because this one is inplace operation\n",
    "        return x\n",
    "\n",
    "class FiLM(nn.Module):\n",
    "    def __init__(self, n_vocab=58, n_resblock=4):\n",
    "        super(FiLM, self).__init__()\n",
    "        self.stem = stem()\n",
    "        self.resblocks = nn.ModuleList()\n",
    "        for i in range(n_resblock):\n",
    "            self.resblocks.append(resblock(128,128))\n",
    "        self.classifier = Classifier(n_classes = n_vocab)\n",
    "        # self.stem=build_stem\n",
    "\n",
    "    def forward(self, fe_image, question):\n",
    "        img = self.stem(fe_image)\n",
    "        for i, resblock in enumerate(self.resblocks):\n",
    "            img = resblock(img, question)\n",
    "            # print(img.size())\n",
    "        out = self.classifier(img)\n",
    "        # print(out.size())\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c-2zaFKf9nq6",
    "tags": []
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "#import enchant\n",
    "\n",
    "from numpy import prod\n",
    "from nltk.corpus import wordnet as wn\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "\n",
    "\n",
    "def file2list(filepath):\n",
    "    with open(filepath,'r') as f:\n",
    "        lines =[k for k in \n",
    "            [k.strip() for k in f.readlines()] \n",
    "        if len(k) > 0]\n",
    "\n",
    "    return lines\n",
    "\n",
    "\n",
    "def list2file(filepath,mylist):\n",
    "    mylist='\\n'.join(mylist)\n",
    "    with open(filepath,'w') as f:\n",
    "        f.writelines(mylist)\n",
    "\n",
    "\n",
    "def items2list(x):\n",
    "    \"\"\"\n",
    "    x - string of comma-separated answer items\n",
    "    \"\"\"\n",
    "    return [l.strip() for l in x.split(',')]\n",
    "\n",
    "\n",
    "def fuzzy_set_membership_measure(x,A,m):\n",
    "    \"\"\"\n",
    "    Set membership measure.\n",
    "    x: element\n",
    "    A: set of elements\n",
    "    m: point-wise element-to-element measure m(a,b) ~ similarity(a,b)\n",
    "\n",
    "    This function implments a fuzzy set membership measure:\n",
    "        m(x \\in A) = max_{a \\in A} m(x,a)}\n",
    "    \"\"\"\n",
    "    return 0 if A==[] else max(map(lambda a: m(x,a), A))\n",
    "\n",
    "\n",
    "def score_it(A,T,m):\n",
    "    \"\"\"\n",
    "    A: list of A items \n",
    "    T: list of T items\n",
    "    m: set membership measure\n",
    "        m(a \\in A) gives a membership quality of a into A \n",
    "\n",
    "    This function implements a fuzzy accuracy score:\n",
    "        score(A,T) = min{prod_{a \\in A} m(a \\in T), prod_{t \\in T} m(a \\in A)}\n",
    "        where A and T are set representations of the answers\n",
    "        and m is a measure\n",
    "    \"\"\"\n",
    "    if A==[] and T==[]:\n",
    "        return 1\n",
    "\n",
    "    # print A,T\n",
    "\n",
    "    score_left=0 if A==[] else prod(map(lambda a: m(a,T), A))\n",
    "    score_right=0 if T==[] else prod(map(lambda t: m(t,A),T))\n",
    "    return min(score_left,score_right) \n",
    "\n",
    "\n",
    "# implementations of different measure functions\n",
    "def dirac_measure(a,b):\n",
    "    \"\"\"\n",
    "    Returns 1 iff a=b and 0 otherwise.\n",
    "    \"\"\"\n",
    "    if a==[] or b==[]:\n",
    "        return 0.0\n",
    "    return float(a==b)\n",
    "\n",
    "\n",
    "def wup_measure(a,b,similarity_threshold=0.8):\n",
    "    \"\"\"\n",
    "    Returns Wu-Palmer similarity score.\n",
    "    More specifically, it computes:\n",
    "        max_{x \\in interp(a)} max_{y \\in interp(b)} wup(x,y)\n",
    "        where interp is a 'interpretation field'\n",
    "    \"\"\"\n",
    "    def get_semantic_field(a):\n",
    "        weight = 1.0\n",
    "        semantic_field = wn.synsets(a,pos=wn.NOUN)\n",
    "        return (semantic_field,weight)\n",
    "\n",
    "\n",
    "    def get_stem_word(a):\n",
    "        \"\"\"\n",
    "        Sometimes answer has form word\\d+:wordid.\n",
    "        If so we return word and downweight\n",
    "        \"\"\"\n",
    "        weight = 1.0\n",
    "        return (a,weight)\n",
    "\n",
    "\n",
    "    global_weight=1.0\n",
    "\n",
    "    (a,global_weight_a)=get_stem_word(a)\n",
    "    (b,global_weight_b)=get_stem_word(b)\n",
    "    global_weight = min(global_weight_a,global_weight_b)\n",
    "\n",
    "    if a==b:\n",
    "        # they are the same\n",
    "        return 1.0*global_weight\n",
    "\n",
    "    if a==[] or b==[]:\n",
    "        return 0\n",
    "\n",
    "\n",
    "    interp_a,weight_a = get_semantic_field(a) \n",
    "    interp_b,weight_b = get_semantic_field(b)\n",
    "\n",
    "    if interp_a == [] or interp_b == []:\n",
    "        return 0\n",
    "\n",
    "    # we take the most optimistic interpretation\n",
    "    global_max=0.0\n",
    "    for x in interp_a:\n",
    "        for y in interp_b:\n",
    "            local_score=x.wup_similarity(y)\n",
    "            if local_score > global_max:\n",
    "                global_max=local_score\n",
    "\n",
    "    # we need to use the semantic fields and therefore we downweight\n",
    "    # unless the score is high which indicates both are synonyms\n",
    "    if global_max < similarity_threshold:\n",
    "        interp_weight = 0.1\n",
    "    else:\n",
    "        interp_weight = 1.0\n",
    "\n",
    "    final_score=global_max*weight_a*weight_b*interp_weight*global_weight\n",
    "    return final_score \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "executionInfo": {
     "elapsed": 313,
     "status": "ok",
     "timestamp": 1669493073498,
     "user": {
      "displayName": "Kaan Ozdogru",
      "userId": "11475962799414321632"
     },
     "user_tz": 300
    },
    "id": "wRTXvMM44DdB"
   },
   "outputs": [],
   "source": [
    "def batch_wup_measure(labels, preds):\n",
    "    wup_scores = [wup_measure(answer_space[label], answer_space[pred]) for label, pred in zip(labels, preds)]\n",
    "    return np.sum(wup_scores)\n",
    "\n",
    "\n",
    "def train_model(model, dataloaders, criterion, optimizer, scheduler, num_epochs=2, val_tolerance=2):\n",
    "    since = time.time()\n",
    "    FE = FeatureExtractor_resnet().to(device)\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "    best_val_loss = [np.Inf] * val_tolerance\n",
    "    early_stop = False\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "            running_wups = 0.0\n",
    "\n",
    "            # Iterate over data.\n",
    "            with tqdm.tqdm(dataloaders[phase], unit='batch') as tepoch:\n",
    "                for img, question_embedding, question, answer in tepoch:\n",
    "                    img = img.to(device)\n",
    "                    answer = answer.to(device)\n",
    "                    question_embedding = question_embedding.to(device)\n",
    "                    context = question_embedding\n",
    "                    img = FE(img)\n",
    "\n",
    "                    # zero the parameter gradients\n",
    "                    optimizer.zero_grad()\n",
    "\n",
    "                    # forward\n",
    "                    # track history if only in train\n",
    "                    with torch.set_grad_enabled(phase == 'train'):\n",
    "                        outputs = model(img,question_embedding)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        loss = criterion(outputs, answer)\n",
    "                        # backward + optimize only if in training phase\n",
    "                        if phase == 'train':\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "\n",
    "                    # statistics\n",
    "                    running_loss += loss.item() * img.size(0)\n",
    "                    running_corrects += torch.sum(preds == answer.data)\n",
    "                    running_wups += batch_wup_measure(answer.data, preds)\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "            epoch_wups = running_wups / dataset_sizes[phase]\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f} WUPS: {epoch_wups:.4f}')\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val': \n",
    "                if epoch_acc > best_acc:\n",
    "                    best_acc = epoch_acc\n",
    "                    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                worst_loss = max(best_val_loss)\n",
    "                if epoch_loss > worst_loss:\n",
    "                    early_stop = True\n",
    "                    break\n",
    "                else:\n",
    "                    best_val_loss[np.argmax(best_val_loss)] = epoch_loss\n",
    "        print(best_val_loss)\n",
    "        if early_stop:\n",
    "            print(\"Training early stopped\")\n",
    "            break\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
    "    print(f'Best val Acc: {best_acc:4f}')\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 236604,
     "status": "ok",
     "timestamp": 1669497666573,
     "user": {
      "displayName": "Kaan Ozdogru",
      "userId": "11475962799414321632"
     },
     "user_tz": 300
    },
    "id": "uzepOQZZ87DQ",
    "outputId": "cda11d89-a046-4e37-a0cc-b0ab5300ed46",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1177/1177 [18:18<00:00,  1.07batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 1.3622 Acc: 0.4688 WUPS: 0.6351\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 295/295 [02:34<00:00,  1.91batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.1525 Acc: 0.5340 WUPS: 0.6815\n",
      "[1.152493347317965, inf, inf, inf, inf]\n",
      "Epoch 1/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 295/295 [02:35<00:00,  1.90batch/s]s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 1.0467 Acc: 0.5768 WUPS: 0.7202\n",
      "[1.152493347317965, 1.0466859032544702, inf, inf, inf]\n",
      "Epoch 2/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1177/1177 [18:21<00:00,  1.07batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.9698 Acc: 0.5851 WUPS: 0.7319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 295/295 [02:37<00:00,  1.87batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.9851 Acc: 0.5867 WUPS: 0.7377\n",
      "[1.152493347317965, 1.0466859032544702, 0.98512948632025, inf, inf]\n",
      "Epoch 3/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1177/1177 [18:22<00:00,  1.07batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.9149 Acc: 0.6110 WUPS: 0.7543\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 295/295 [02:39<00:00,  1.85batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.9860 Acc: 0.5929 WUPS: 0.7437\n",
      "[1.152493347317965, 1.0466859032544702, 0.98512948632025, 0.9860179554981721, inf]\n",
      "Epoch 4/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1177/1177 [18:26<00:00,  1.06batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.8754 Acc: 0.6300 WUPS: 0.7706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 295/295 [02:37<00:00,  1.87batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.9646 Acc: 0.6041 WUPS: 0.7444\n",
      "[1.152493347317965, 1.0466859032544702, 0.98512948632025, 0.9860179554981721, 0.9645542593459755]\n",
      "Epoch 5/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1177/1177 [18:10<00:00,  1.08batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.8576 Acc: 0.6420 WUPS: 0.7801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 295/295 [02:36<00:00,  1.88batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.9562 Acc: 0.6080 WUPS: 0.7523\n",
      "[0.956210380277813, 1.0466859032544702, 0.98512948632025, 0.9860179554981721, 0.9645542593459755]\n",
      "Epoch 6/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1177/1177 [18:07<00:00,  1.08batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.8117 Acc: 0.6612 WUPS: 0.7953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 295/295 [02:34<00:00,  1.91batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.9518 Acc: 0.6253 WUPS: 0.7643\n",
      "[0.956210380277813, 0.9518143156693565, 0.98512948632025, 0.9860179554981721, 0.9645542593459755]\n",
      "Epoch 7/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1177/1177 [18:02<00:00,  1.09batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.7021 Acc: 0.7063 WUPS: 0.8282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 295/295 [02:33<00:00,  1.92batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.9424 Acc: 0.6335 WUPS: 0.7699\n",
      "[0.956210380277813, 0.9518143156693565, 0.98512948632025, 0.9423781541307433, 0.9645542593459755]\n",
      "Epoch 8/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1177/1177 [18:03<00:00,  1.09batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6696 Acc: 0.7201 WUPS: 0.8393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 295/295 [02:33<00:00,  1.92batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.9531 Acc: 0.6307 WUPS: 0.7698\n",
      "[0.956210380277813, 0.9518143156693565, 0.9530520870178244, 0.9423781541307433, 0.9645542593459755]\n",
      "Epoch 9/19\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1177/1177 [18:03<00:00,  1.09batch/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.6494 Acc: 0.7302 WUPS: 0.8468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 295/295 [02:34<00:00,  1.91batch/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val Loss: 0.9769 Acc: 0.6308 WUPS: 0.7702\n",
      "[0.956210380277813, 0.9518143156693565, 0.9530520870178244, 0.9423781541307433, 0.9645542593459755]\n",
      "Training early stopped\n",
      "Training complete in 208m 6s\n",
      "Best val Acc: 0.633486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import lr_scheduler\n",
    "\n",
    "model = FiLM().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(DRAW(data=train_data, transform=transform), batch_size=batch_size, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(DRAW(data=val_data, transform=transform), batch_size=batch_size, shuffle=True)\n",
    "dataloaders_dict = {'train':train_loader,'val':val_loader}\n",
    "dataset_sizes = {'train': len(train_data), 'val': len(val_data)}\n",
    "\n",
    "model_ft = train_model(model, dataloaders_dict, criterion, optimizer, exp_lr_scheduler,\n",
    "                       num_epochs=20, val_tolerance=5)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "Gs97AkXNcTyr",
    "C4KLZwwl9xDZ",
    "wRCj0xu-vI9x",
    "yNwrqy2nvL42"
   ],
   "provenance": []
  },
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-12.m100",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-12:m100"
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
